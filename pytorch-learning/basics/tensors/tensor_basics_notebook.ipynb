{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§  PyTorch å¼ é‡åŸºç¡€æ•™ç¨‹\n",
    "\n",
    "## ğŸ“š æœ¬èŠ‚å­¦ä¹ ç›®æ ‡\n",
    "- ç†è§£å¼ é‡(Tensor)çš„åŸºæœ¬æ¦‚å¿µ\n",
    "- æŒæ¡å¼ é‡çš„åˆ›å»ºæ–¹æ³•\n",
    "- å­¦ä¼šå¼ é‡çš„åŸºæœ¬æ“ä½œå’Œå±æ€§\n",
    "- ç†Ÿæ‚‰å¼ é‡çš„å½¢çŠ¶å˜æ¢\n",
    "- æŒæ¡å¼ é‡çš„æ•°å­¦è¿ç®—\n",
    "- äº†è§£å¼ é‡ä¸NumPyçš„å…³ç³»\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ PyTorch ç‰ˆæœ¬: 2.7.1+cu126\n",
      "ğŸš€ ä½¿ç”¨ CUDA: NVIDIA GeForce GTX 1050 Ti\n",
      "ğŸ“Š CUDA å†…å­˜: 4.2 GB\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„,å®šä½é¡¹ç›®ä¸­çš„æ–‡ä»¶æˆ–ç›®å½•ï¼Œæ–¹ä¾¿è·¨æ¨¡å—å¼•ç”¨ã€‚\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "from utils.common import get_device, print_tensor_info\n",
    "\n",
    "print(f\"ğŸ”¥ PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ 1. ä»€ä¹ˆæ˜¯å¼ é‡ï¼Ÿ\n",
    "\n",
    "**å¼ é‡(Tensor)** æ˜¯PyTorchä¸­æœ€åŸºæœ¬çš„æ•°æ®ç»“æ„ï¼Œå¯ä»¥ç†è§£ä¸ºï¼š\n",
    "\n",
    "- **0ç»´å¼ é‡**: æ ‡é‡ (scalar) - ä¸€ä¸ªæ•°å­—\n",
    "- **1ç»´å¼ é‡**: å‘é‡ (vector) - ä¸€è¡Œæ•°å­—\n",
    "- **2ç»´å¼ é‡**: çŸ©é˜µ (matrix) - è¡¨æ ¼å½¢å¼çš„æ•°æ®\n",
    "- **3ç»´å¼ é‡**: ç«‹æ–¹ä½“ - æ¯”å¦‚RGBå›¾åƒ (é«˜Ã—å®½Ã—é€šé“)\n",
    "- **4ç»´å¼ é‡**: ä¸€æ‰¹å›¾åƒ (æ‰¹æ¬¡Ã—é€šé“Ã—é«˜Ã—å®½)\n",
    "- **æ›´é«˜ç»´**: å¤æ‚çš„å¤šç»´æ•°æ®\n",
    "\n",
    "### ğŸ­ ç”Ÿæ´»ä¸­çš„ç±»æ¯”\n",
    "- **æ ‡é‡**: æ¸©åº¦ (23.5Â°C)\n",
    "- **å‘é‡**: ä¸€å¤©çš„æ¸©åº¦è®°å½• [20, 22, 25, 28, 26]\n",
    "- **çŸ©é˜µ**: ä¸€å‘¨çš„æ¸©åº¦è®°å½•è¡¨\n",
    "- **3ç»´å¼ é‡**: ä¸€ä¸ªæœˆæ¯å¤©æ¯å°æ—¶çš„æ¸©åº¦è®°å½•\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ 2. å¼ é‡çš„åˆ›å»ºæ–¹æ³•\n",
    "\n",
    "è®©æˆ‘ä»¬å­¦ä¹ å„ç§åˆ›å»ºå¼ é‡çš„æ–¹æ³•ï¼š\n",
    "\n",
    "### 2.1 ä»æ•°æ®ç›´æ¥åˆ›å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¢ ä»åˆ—è¡¨åˆ›å»ºå¼ é‡ï¼š\n",
      "ğŸ“Š æ ‡é‡ ä¿¡æ¯:\n",
      "  å½¢çŠ¶: torch.Size([])\n",
      "  æ•°æ®ç±»å‹: torch.int64\n",
      "  è®¾å¤‡: cpu\n",
      "  å†…å­˜å ç”¨: 0.00 MB\n",
      "  å€¼: 42\n",
      "\n",
      "ğŸ“Š å‘é‡ ä¿¡æ¯:\n",
      "  å½¢çŠ¶: torch.Size([5])\n",
      "  æ•°æ®ç±»å‹: torch.int64\n",
      "  è®¾å¤‡: cpu\n",
      "  å†…å­˜å ç”¨: 0.00 MB\n",
      "  å€¼: tensor([1, 2, 3, 4, 5])\n",
      "\n",
      "ğŸ“Š çŸ©é˜µ ä¿¡æ¯:\n",
      "  å½¢çŠ¶: torch.Size([2, 3])\n",
      "  æ•°æ®ç±»å‹: torch.int64\n",
      "  è®¾å¤‡: cpu\n",
      "  å†…å­˜å ç”¨: 0.00 MB\n",
      "  å€¼: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "ğŸ“Š 3ç»´å¼ é‡ ä¿¡æ¯:\n",
      "  å½¢çŠ¶: torch.Size([2, 2, 2])\n",
      "  æ•°æ®ç±»å‹: torch.int64\n",
      "  è®¾å¤‡: cpu\n",
      "  å†…å­˜å ç”¨: 0.00 MB\n",
      "  å€¼: tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š ä»Pythonåˆ—è¡¨åˆ›å»ºå¼ é‡\n",
    "print(\"ğŸ”¢ ä»åˆ—è¡¨åˆ›å»ºå¼ é‡ï¼š\")\n",
    "\n",
    "# 0ç»´å¼ é‡ (æ ‡é‡)\n",
    "scalar = torch.tensor(42)\n",
    "print_tensor_info(scalar, \"æ ‡é‡\")\n",
    "print()\n",
    "\n",
    "# 1ç»´å¼ é‡ (å‘é‡)\n",
    "vector = torch.tensor([1, 2, 3, 4, 5])\n",
    "print_tensor_info(vector, \"å‘é‡\")\n",
    "print()\n",
    "\n",
    "# 2ç»´å¼ é‡ (çŸ©é˜µ)\n",
    "matrix = torch.tensor([[1, 2, 3], \n",
    "                      [4, 5, 6]])\n",
    "print_tensor_info(matrix, \"çŸ©é˜µ\")\n",
    "print()\n",
    "\n",
    "# 3ç»´å¼ é‡\n",
    "tensor_3d = torch.tensor([[[1, 2], [3, 4]], \n",
    "                         [[5, 6], [7, 8]]])\n",
    "print_tensor_info(tensor_3d, \"3ç»´å¼ é‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ç‰¹æ®Šå€¼å¼ é‡çš„åˆ›å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¨ åˆ›å»ºç‰¹æ®Šå€¼å¼ é‡ï¼š\n",
      "å…¨é›¶å¼ é‡ (3x4):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "\n",
      "å…¨ä¸€å¼ é‡ (2x3):\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "å•ä½çŸ©é˜µ (3x3):\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "\n",
      "å¡«å……7.5çš„å¼ é‡ (2x3):\n",
      "tensor([[7.5000, 7.5000, 7.5000],\n",
      "        [7.5000, 7.5000, 7.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ¨ åˆ›å»ºç‰¹æ®Šå€¼å¼ é‡ï¼š\")\n",
    "\n",
    "# å…¨é›¶å¼ é‡\n",
    "zeros = torch.zeros(3, 4)\n",
    "print(f\"å…¨é›¶å¼ é‡ (3x4):\\n{zeros}\\n\")\n",
    "\n",
    "# å…¨ä¸€å¼ é‡\n",
    "ones = torch.ones(2, 3)\n",
    "print(f\"å…¨ä¸€å¼ é‡ (2x3):\\n{ones}\\n\")\n",
    "\n",
    "# å¯¹è§’çº¿ä¸º1çš„å•ä½çŸ©é˜µ\n",
    "eye = torch.eye(3)\n",
    "print(f\"å•ä½çŸ©é˜µ (3x3):\\n{eye}\\n\")\n",
    "\n",
    "# å¡«å……ç‰¹å®šå€¼\n",
    "filled = torch.full((2, 3), 7.5)\n",
    "print(f\"å¡«å……7.5çš„å¼ é‡ (2x3):\\n{filled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 éšæœºå¼ é‡çš„åˆ›å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ² åˆ›å»ºéšæœºå¼ é‡ï¼š\n",
      "å‡åŒ€åˆ†å¸ƒéšæœºå¼ é‡ [0,1):\n",
      "tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009]])\n",
      "\n",
      "æ­£æ€åˆ†å¸ƒéšæœºå¼ é‡ N(0,1):\n",
      "tensor([[ 1.1561,  0.3965, -2.4661],\n",
      "        [ 0.3623,  0.3765, -0.1808]])\n",
      "\n",
      "éšæœºæ•´æ•°å¼ é‡ [0,10):\n",
      "tensor([[7, 6, 9],\n",
      "        [6, 3, 1]])\n",
      "\n",
      "ä¸matrixç›¸åŒå½¢çŠ¶çš„éšæœºå¼ é‡:\n",
      "tensor([[ 1.1103, -1.6898, -0.9890],\n",
      "        [ 0.9580,  1.3221,  0.8172]])\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ² åˆ›å»ºéšæœºå¼ é‡ï¼š\")\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ä»¥ä¾¿ç»“æœå¯é‡ç°\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 0-1ä¹‹é—´çš„å‡åŒ€åˆ†å¸ƒéšæœºæ•°\n",
    "random_uniform = torch.rand(2, 3)\n",
    "print(f\"å‡åŒ€åˆ†å¸ƒéšæœºå¼ é‡ [0,1):\\n{random_uniform}\\n\")\n",
    "\n",
    "# æ ‡å‡†æ­£æ€åˆ†å¸ƒéšæœºæ•° (å‡å€¼0ï¼Œæ ‡å‡†å·®1)\n",
    "random_normal = torch.randn(2, 3)\n",
    "print(f\"æ­£æ€åˆ†å¸ƒéšæœºå¼ é‡ N(0,1):\\n{random_normal}\\n\")\n",
    "\n",
    "# æŒ‡å®šèŒƒå›´çš„éšæœºæ•´æ•°\n",
    "random_int = torch.randint(0, 10, (2, 3))\n",
    "print(f\"éšæœºæ•´æ•°å¼ é‡ [0,10):\\n{random_int}\\n\")\n",
    "\n",
    "# ç±»ä¼¼äºå¦ä¸€ä¸ªå¼ é‡çš„éšæœºå¼ é‡\n",
    "like_tensor = torch.randn_like(matrix.float())\n",
    "print(f\"ä¸matrixç›¸åŒå½¢çŠ¶çš„éšæœºå¼ é‡:\\n{like_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 æ•°å€¼åºåˆ—å¼ é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ åˆ›å»ºæ•°å€¼åºåˆ—å¼ é‡ï¼š\n",
      "ç­‰å·®æ•°åˆ— arange(0, 10, 2): tensor([0, 2, 4, 6, 8])\n",
      "\n",
      "çº¿æ€§ç­‰åˆ† linspace(0, 1, 5): tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n",
      "\n",
      "å¯¹æ•°ç­‰åˆ† logspace(0, 2, 5): tensor([  1.0000,   3.1623,  10.0000,  31.6228, 100.0000])\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“ˆ åˆ›å»ºæ•°å€¼åºåˆ—å¼ é‡ï¼š\")\n",
    "\n",
    "# ç­‰å·®æ•°åˆ—\n",
    "arange_tensor = torch.arange(0, 10, 2)  # ä»0åˆ°10ï¼Œæ­¥é•¿ä¸º2\n",
    "print(f\"ç­‰å·®æ•°åˆ— arange(0, 10, 2): {arange_tensor}\\n\")\n",
    "\n",
    "# çº¿æ€§ç­‰åˆ†\n",
    "linspace_tensor = torch.linspace(0, 1, 5)  # ä»0åˆ°1ï¼Œç­‰åˆ†æˆ5ä¸ªç‚¹\n",
    "print(f\"çº¿æ€§ç­‰åˆ† linspace(0, 1, 5): {linspace_tensor}\\n\")\n",
    "\n",
    "# å¯¹æ•°ç­‰åˆ†\n",
    "logspace_tensor = torch.logspace(0, 2, 5)  # 10^0 åˆ° 10^2ï¼Œç­‰åˆ†æˆ5ä¸ªç‚¹\n",
    "print(f\"å¯¹æ•°ç­‰åˆ† logspace(0, 2, 5): {logspace_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ” 3. å¼ é‡çš„å±æ€§\n",
    "\n",
    "æ¯ä¸ªå¼ é‡éƒ½æœ‰å‡ ä¸ªé‡è¦çš„å±æ€§ï¼š\n",
    "\n",
    "- **shape/size**: å¼ é‡çš„å½¢çŠ¶\n",
    "- **dtype**: æ•°æ®ç±»å‹\n",
    "- **device**: å­˜å‚¨è®¾å¤‡(CPU/GPU)\n",
    "- **requires_grad**: æ˜¯å¦éœ€è¦è®¡ç®—æ¢¯åº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” å¼ é‡å±æ€§è¯¦è§£ï¼š\n",
      "tensor([[[ 0.1391, -0.1082, -0.7174,  0.7566,  0.3715],\n",
      "         [-1.0049,  0.0083,  0.3277,  0.2829, -0.8926],\n",
      "         [-0.1626, -0.8062, -0.1168, -1.6124, -0.1541],\n",
      "         [-0.0646, -0.5324,  0.0533, -0.0314, -0.7431]],\n",
      "\n",
      "        [[-1.1582, -0.0249, -0.7584, -0.4157,  0.6389],\n",
      "         [-0.2545, -1.2304, -1.5822,  0.6431,  0.9715],\n",
      "         [-1.3249, -1.0006, -0.4556,  0.4031, -0.7707],\n",
      "         [-1.1757, -0.1555, -0.6527,  0.2520,  0.4590]],\n",
      "\n",
      "        [[ 1.8932,  0.1633, -0.2634, -1.1079,  0.7673],\n",
      "         [-1.1230,  0.3047,  0.3896, -0.2520, -1.0066],\n",
      "         [ 0.2927, -1.1003,  1.9016, -1.5185,  1.6850],\n",
      "         [-1.3713,  0.2893,  0.3939,  0.6529, -0.5519]]], device='cuda:0')\n",
      "ğŸ“ å½¢çŠ¶ (shape): torch.Size([3, 4, 5])\n",
      "ğŸ“ å¤§å° (size): torch.Size([3, 4, 5])\n",
      "ğŸ”¢ ç»´åº¦æ•° (ndim): 3\n",
      "ğŸ“Š å…ƒç´ æ€»æ•° (numel): 60\n",
      "ğŸ­ æ•°æ®ç±»å‹ (dtype): torch.float32\n",
      "ğŸ’» è®¾å¤‡ (device): cuda:0\n",
      "ğŸ§® éœ€è¦æ¢¯åº¦ (requires_grad): False\n",
      "ğŸ’¾ å†…å­˜å¸ƒå±€ (layout): torch.strided\n",
      "ğŸ“ æ­¥é•¿ (stride): (20, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºä¸€ä¸ªç¤ºä¾‹å¼ é‡\n",
    "example_tensor = torch.randn(3, 4, 5, dtype=torch.float32, device=device)\n",
    "\n",
    "print(\"ğŸ” å¼ é‡å±æ€§è¯¦è§£ï¼š\")\n",
    "print(example_tensor)\n",
    "\n",
    "print(f\"ğŸ“ å½¢çŠ¶ (shape): {example_tensor.shape}\")\n",
    "print(f\"ğŸ“ å¤§å° (size): {example_tensor.size()}\")\n",
    "print(f\"ğŸ”¢ ç»´åº¦æ•° (ndim): {example_tensor.ndim}\")\n",
    "print(f\"ğŸ“Š å…ƒç´ æ€»æ•° (numel): {example_tensor.numel()}\")\n",
    "print(f\"ğŸ­ æ•°æ®ç±»å‹ (dtype): {example_tensor.dtype}\")\n",
    "print(f\"ğŸ’» è®¾å¤‡ (device): {example_tensor.device}\")\n",
    "print(f\"ğŸ§® éœ€è¦æ¢¯åº¦ (requires_grad): {example_tensor.requires_grad}\")\n",
    "print(f\"ğŸ’¾ å†…å­˜å¸ƒå±€ (layout): {example_tensor.layout}\")\n",
    "print(f\"ğŸ“ æ­¥é•¿ (stride): {example_tensor.stride()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 æ•°æ®ç±»å‹è¯¦è§£\n",
    "\n",
    "PyTorchæ”¯æŒå¤šç§æ•°æ®ç±»å‹ï¼Œé€‰æ‹©åˆé€‚çš„æ•°æ®ç±»å‹å¾ˆé‡è¦ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ­ å¸¸ç”¨æ•°æ®ç±»å‹ï¼š\n",
      "int32: tensor([1, 2, 3], dtype=torch.int32), dtype: torch.int32\n",
      "long: tensor([1, 2, 3]), dtype: torch.int64\n",
      "float32: tensor([1., 2., 3.]), dtype: torch.float32\n",
      "double: tensor([1., 2., 3.], dtype=torch.float64), dtype: torch.float64\n",
      "bool: tensor([ True, False,  True]), dtype: torch.bool\n",
      "\n",
      "ğŸ’¡ ç±»å‹è½¬æ¢ï¼š\n",
      "int32 â†’ float32: tensor([1., 2., 3.]), dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ­ å¸¸ç”¨æ•°æ®ç±»å‹ï¼š\")\n",
    "\n",
    "# æ•´æ•°ç±»å‹\n",
    "int_tensor = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
    "print(f\"int32: {int_tensor}, dtype: {int_tensor.dtype}\")\n",
    "\n",
    "# é•¿æ•´æ•°ç±»å‹ (é»˜è®¤æ•´æ•°ç±»å‹)\n",
    "long_tensor = torch.tensor([1, 2, 3], dtype=torch.long)\n",
    "print(f\"long: {long_tensor}, dtype: {long_tensor.dtype}\")\n",
    "\n",
    "# å•ç²¾åº¦æµ®ç‚¹æ•° (é»˜è®¤æµ®ç‚¹ç±»å‹)\n",
    "float_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "print(f\"float32: {float_tensor}, dtype: {float_tensor.dtype}\")\n",
    "\n",
    "# åŒç²¾åº¦æµ®ç‚¹æ•°\n",
    "double_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.double)\n",
    "print(f\"double: {double_tensor}, dtype: {double_tensor.dtype}\")\n",
    "\n",
    "# å¸ƒå°”ç±»å‹\n",
    "bool_tensor = torch.tensor([True, False, True], dtype=torch.bool)\n",
    "print(f\"bool: {bool_tensor}, dtype: {bool_tensor.dtype}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ç±»å‹è½¬æ¢ï¼š\")\n",
    "# ç±»å‹è½¬æ¢\n",
    "converted = int_tensor.float()  # è½¬æ¢ä¸ºfloat32\n",
    "print(f\"int32 â†’ float32: {converted}, dtype: {converted.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”„ 4. å¼ é‡çš„å½¢çŠ¶æ“ä½œ\n",
    "\n",
    "**å½¢çŠ¶æ“ä½œæ˜¯æ·±åº¦å­¦ä¹ ä¸­æœ€å¸¸ç”¨çš„æ“ä½œä¹‹ä¸€ï¼Œè®©æˆ‘ä»¬è¯¦ç»†å­¦ä¹ ï¼š**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ åŸå§‹å¼ é‡ x:\n",
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "å½¢çŠ¶: torch.Size([2, 3, 4])\n",
      "\n",
      "ğŸ”„ å½¢çŠ¶å˜æ¢æ“ä½œï¼š\n",
      "reshape(4, 6):\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]])\n",
      "å½¢çŠ¶: torch.Size([4, 6])\n",
      "\n",
      "view(3, 8):\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [16, 17, 18, 19, 20, 21, 22, 23]])\n",
      "å½¢çŠ¶: torch.Size([3, 8])\n",
      "\n",
      "flatten(): tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23])\n",
      "å½¢çŠ¶: torch.Size([24])\n",
      "\n",
      "squeezeå‰å½¢çŠ¶: torch.Size([1, 3, 1, 4])\n",
      "squeezeåå½¢çŠ¶: torch.Size([3, 4])\n",
      "\n",
      "unsqueeze(0)å‰å½¢çŠ¶: torch.Size([2, 3, 4])\n",
      "unsqueeze(0)åå½¢çŠ¶: torch.Size([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºä¸€ä¸ªç¤ºä¾‹å¼ é‡\n",
    "x = torch.arange(24).reshape(2, 3, 4)\n",
    "print(f\"ğŸ¯ åŸå§‹å¼ é‡ x:\\n{x}\")\n",
    "print(f\"å½¢çŠ¶: {x.shape}\\n\")\n",
    "\n",
    "print(\"ğŸ”„ å½¢çŠ¶å˜æ¢æ“ä½œï¼š\")\n",
    "\n",
    "# 1. reshape: æ”¹å˜å½¢çŠ¶ä½†ä¿æŒå…ƒç´ æ€»æ•°ä¸å˜\n",
    "reshaped = x.reshape(4, 6)\n",
    "print(f\"reshape(4, 6):\\n{reshaped}\")\n",
    "print(f\"å½¢çŠ¶: {reshaped.shape}\\n\")\n",
    "\n",
    "# 2. view: ç±»ä¼¼reshapeä½†è¦æ±‚å†…å­˜è¿ç»­\n",
    "viewed = x.view(3, 8)\n",
    "print(f\"view(3, 8):\\n{viewed}\")\n",
    "print(f\"å½¢çŠ¶: {viewed.shape}\\n\")\n",
    "\n",
    "# 3. flatten: å±•å¹³ä¸º1ç»´\n",
    "flattened = x.flatten()\n",
    "print(f\"flatten(): {flattened}\")\n",
    "print(f\"å½¢çŠ¶: {flattened.shape}\\n\")\n",
    "\n",
    "# 4. squeeze: ç§»é™¤å¤§å°ä¸º1çš„ç»´åº¦\n",
    "squeezed_tensor = torch.randn(1, 3, 1, 4)\n",
    "squeezed = squeezed_tensor.squeeze()\n",
    "print(f\"squeezeå‰å½¢çŠ¶: {squeezed_tensor.shape}\")\n",
    "print(f\"squeezeåå½¢çŠ¶: {squeezed.shape}\\n\")\n",
    "\n",
    "# 5. unsqueeze: æ·»åŠ å¤§å°ä¸º1çš„ç»´åº¦\n",
    "unsqueezed = x.unsqueeze(0)  # åœ¨ä½ç½®0æ·»åŠ ç»´åº¦\n",
    "print(f\"unsqueeze(0)å‰å½¢çŠ¶: {x.shape}\")\n",
    "print(f\"unsqueeze(0)åå½¢çŠ¶: {unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 ç»´åº¦ç½®æ¢å’Œè½¬ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”„ ç»´åº¦ç½®æ¢æ“ä½œï¼š\")\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª3ç»´å¼ é‡ (æ‰¹æ¬¡, é«˜åº¦, å®½åº¦)\n",
    "image_like = torch.randn(2, 28, 28)\n",
    "print(f\"åŸå§‹å½¢çŠ¶ (batch, height, width): {image_like.shape}\")\n",
    "\n",
    "# transpose: äº¤æ¢ä¸¤ä¸ªç»´åº¦\n",
    "transposed = image_like.transpose(1, 2)  # äº¤æ¢ç»´åº¦1å’Œ2\n",
    "print(f\"transpose(1, 2)åå½¢çŠ¶: {transposed.shape}\")\n",
    "\n",
    "# permute: é‡æ–°æ’åˆ—æ‰€æœ‰ç»´åº¦\n",
    "permuted = image_like.permute(2, 0, 1)  # é‡æ’ä¸º (width, batch, height)\n",
    "print(f\"permute(2, 0, 1)åå½¢çŠ¶: {permuted.shape}\")\n",
    "\n",
    "# å¯¹äº2DçŸ©é˜µï¼Œå¯ä»¥ç”¨.Tè¿›è¡Œè½¬ç½®\n",
    "matrix_2d = torch.randn(3, 4)\n",
    "print(f\"\\n2DçŸ©é˜µè½¬ç½®ï¼š\")\n",
    "print(f\"åŸå§‹å½¢çŠ¶: {matrix_2d.shape}\")\n",
    "print(f\"è½¬ç½®åå½¢çŠ¶: {matrix_2d.T.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§® 5. å¼ é‡çš„æ•°å­¦è¿ç®—\n",
    "\n",
    "PyTorchæä¾›äº†ä¸°å¯Œçš„æ•°å­¦è¿ç®—ï¼Œæ”¯æŒå…ƒç´ çº§è¿ç®—å’ŒçŸ©é˜µè¿ç®—ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§® åŸºæœ¬æ•°å­¦è¿ç®—ï¼š\")\n",
    "\n",
    "# åˆ›å»ºä¸¤ä¸ªç¤ºä¾‹å¼ é‡\n",
    "a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
    "\n",
    "print(f\"å¼ é‡ a:\\n{a}\")\n",
    "print(f\"å¼ é‡ b:\\n{b}\\n\")\n",
    "\n",
    "# å…ƒç´ çº§è¿ç®—\n",
    "print(\"ğŸ”¢ å…ƒç´ çº§è¿ç®—ï¼š\")\n",
    "print(f\"åŠ æ³• a + b:\\n{a + b}\\n\")\n",
    "print(f\"å‡æ³• a - b:\\n{a - b}\\n\")\n",
    "print(f\"ä¹˜æ³• a * b (å…ƒç´ çº§):\\n{a * b}\\n\")\n",
    "print(f\"é™¤æ³• a / b:\\n{a / b}\\n\")\n",
    "print(f\"å¹‚è¿ç®— a ** 2:\\n{a ** 2}\\n\")\n",
    "\n",
    "# çŸ©é˜µè¿ç®—\n",
    "print(\"ğŸ“Š çŸ©é˜µè¿ç®—ï¼š\")\n",
    "print(f\"çŸ©é˜µä¹˜æ³• a @ b:\\n{a @ b}\\n\")\n",
    "print(f\"çŸ©é˜µä¹˜æ³• torch.mm(a, b):\\n{torch.mm(a, b)}\\n\")\n",
    "\n",
    "# å¹¿æ’­æœºåˆ¶\n",
    "print(\"ğŸ“¡ å¹¿æ’­æœºåˆ¶ï¼š\")\n",
    "scalar = 10\n",
    "print(f\"å¼ é‡ä¸æ ‡é‡è¿ç®— a + {scalar}:\\n{a + scalar}\\n\")\n",
    "\n",
    "vector = torch.tensor([1, 2])\n",
    "print(f\"å¼ é‡ä¸å‘é‡è¿ç®— a + {vector}:\\n{a + vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 èšåˆè¿ç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“Š èšåˆè¿ç®—ï¼š\")\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªç¤ºä¾‹å¼ é‡\n",
    "data = torch.randn(3, 4)\n",
    "print(f\"ç¤ºä¾‹æ•°æ®:\\n{data}\\n\")\n",
    "\n",
    "# ç»Ÿè®¡è¿ç®—\n",
    "print(f\"æ±‚å’Œ sum(): {data.sum()}\")\n",
    "print(f\"å¹³å‡å€¼ mean(): {data.mean():.4f}\")\n",
    "print(f\"æœ€å¤§å€¼ max(): {data.max()}\")\n",
    "print(f\"æœ€å°å€¼ min(): {data.min()}\")\n",
    "print(f\"æ ‡å‡†å·® std(): {data.std():.4f}\")\n",
    "print(f\"æ–¹å·® var(): {data.var():.4f}\\n\")\n",
    "\n",
    "# æŒ‰ç»´åº¦èšåˆ\n",
    "print(\"æŒ‰ç»´åº¦èšåˆï¼š\")\n",
    "print(f\"æŒ‰è¡Œæ±‚å’Œ sum(dim=1): {data.sum(dim=1)}\")\n",
    "print(f\"æŒ‰åˆ—æ±‚å’Œ sum(dim=0): {data.sum(dim=0)}\")\n",
    "print(f\"æŒ‰è¡Œæ±‚å¹³å‡ mean(dim=1): {data.mean(dim=1)}\")\n",
    "\n",
    "# ä¿æŒç»´åº¦\n",
    "print(f\"\\nä¿æŒç»´åº¦ sum(dim=1, keepdim=True):\\n{data.sum(dim=1, keepdim=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 æ•°å­¦å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”¬ æ•°å­¦å‡½æ•°ï¼š\")\n",
    "\n",
    "# åˆ›å»ºæµ‹è¯•æ•°æ®\n",
    "x = torch.linspace(-2, 2, 5)\n",
    "print(f\"è¾“å…¥ x: {x}\\n\")\n",
    "\n",
    "# æ¿€æ´»å‡½æ•°\n",
    "print(\"ğŸ§  æ¿€æ´»å‡½æ•°ï¼š\")\n",
    "print(f\"ReLU: {torch.relu(x)}\")\n",
    "print(f\"Sigmoid: {torch.sigmoid(x)}\")\n",
    "print(f\"Tanh: {torch.tanh(x)}\\n\")\n",
    "\n",
    "# ä¸‰è§’å‡½æ•°\n",
    "print(\"ğŸ“ ä¸‰è§’å‡½æ•°ï¼š\")\n",
    "print(f\"Sin: {torch.sin(x)}\")\n",
    "print(f\"Cos: {torch.cos(x)}\\n\")\n",
    "\n",
    "# æŒ‡æ•°å’Œå¯¹æ•°\n",
    "positive_x = torch.abs(x) + 0.1  # ç¡®ä¿ä¸ºæ­£æ•°\n",
    "print(\"ğŸ“ˆ æŒ‡æ•°å’Œå¯¹æ•°ï¼š\")\n",
    "print(f\"æŒ‡æ•° exp: {torch.exp(x)}\")\n",
    "print(f\"å¯¹æ•° log: {torch.log(positive_x)}\")\n",
    "print(f\"å¼€æ–¹ sqrt: {torch.sqrt(positive_x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ 6. ç´¢å¼•å’Œåˆ‡ç‰‡\n",
    "\n",
    "å¼ é‡çš„ç´¢å¼•å’Œåˆ‡ç‰‡æ“ä½œç±»ä¼¼äºNumPyï¼Œä½†æœ‰ä¸€äº›PyTorchç‰¹æœ‰çš„åŠŸèƒ½ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ ç´¢å¼•å’Œåˆ‡ç‰‡æ“ä½œï¼š\")\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª3ç»´å¼ é‡\n",
    "tensor_3d = torch.arange(24).reshape(2, 3, 4)\n",
    "print(f\"åŸå§‹3Då¼ é‡:\\n{tensor_3d}\\n\")\n",
    "\n",
    "print(\"ğŸ” åŸºæœ¬ç´¢å¼•ï¼š\")\n",
    "print(f\"ç¬¬0ä¸ªå…ƒç´  [0]: \\n{tensor_3d[0]}\\n\")\n",
    "print(f\"ç¬¬0è¡Œç¬¬1åˆ— [0, 1]: {tensor_3d[0, 1]}\\n\")\n",
    "print(f\"ç‰¹å®šå…ƒç´  [0, 1, 2]: {tensor_3d[0, 1, 2]}\\n\")\n",
    "\n",
    "print(\"âœ‚ï¸ åˆ‡ç‰‡æ“ä½œï¼š\")\n",
    "print(f\"å‰ä¸¤è¡Œ [:2]: \\n{tensor_3d[:2]}\\n\")\n",
    "print(f\"æ‰€æœ‰è¡Œçš„ç¬¬1åˆ— [:, 1]: \\n{tensor_3d[:, 1]}\\n\")\n",
    "print(f\"æœ€åä¸¤åˆ— [:, :, -2:]: \\n{tensor_3d[:, :, -2:]}\\n\")\n",
    "\n",
    "print(\"ğŸ² é«˜çº§ç´¢å¼•ï¼š\")\n",
    "# å¸ƒå°”ç´¢å¼•\n",
    "mask = tensor_3d > 10\n",
    "masked_values = tensor_3d[mask]\n",
    "print(f\"å¤§äº10çš„å…ƒç´ : {masked_values}\\n\")\n",
    "\n",
    "# èŠ±å¼ç´¢å¼•\n",
    "indices = torch.tensor([0, 1, 0])\n",
    "selected = tensor_3d[indices]\n",
    "print(f\"é€‰æ‹©ç‰¹å®šç´¢å¼• [0, 1, 0]: \\n{selected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”— 7. å¼ é‡çš„æ‹¼æ¥å’Œåˆ†å‰²\n",
    "\n",
    "åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œç»å¸¸éœ€è¦ç»„åˆæˆ–åˆ†å‰²å¼ é‡ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”— å¼ é‡æ‹¼æ¥å’Œåˆ†å‰²ï¼š\")\n",
    "\n",
    "# åˆ›å»ºä¸¤ä¸ªå¼ é‡\n",
    "t1 = torch.randn(2, 3)\n",
    "t2 = torch.randn(2, 3)\n",
    "print(f\"å¼ é‡1:\\n{t1}\")\n",
    "print(f\"å¼ é‡2:\\n{t2}\\n\")\n",
    "\n",
    "print(\"ğŸ”— æ‹¼æ¥æ“ä½œï¼š\")\n",
    "# æŒ‰è¡Œæ‹¼æ¥ (dim=0)\n",
    "cat_dim0 = torch.cat([t1, t2], dim=0)\n",
    "print(f\"æŒ‰è¡Œæ‹¼æ¥ cat(dim=0):\\n{cat_dim0}\\n\")\n",
    "\n",
    "# æŒ‰åˆ—æ‹¼æ¥ (dim=1)\n",
    "cat_dim1 = torch.cat([t1, t2], dim=1)\n",
    "print(f\"æŒ‰åˆ—æ‹¼æ¥ cat(dim=1):\\n{cat_dim1}\\n\")\n",
    "\n",
    "# å †å  - åˆ›å»ºæ–°ç»´åº¦\n",
    "stacked = torch.stack([t1, t2], dim=0)\n",
    "print(f\"å †å  stack(dim=0) å½¢çŠ¶: {stacked.shape}\")\n",
    "print(f\"å †å ç»“æœ:\\n{stacked}\\n\")\n",
    "\n",
    "print(\"âœ‚ï¸ åˆ†å‰²æ“ä½œï¼š\")\n",
    "# ç­‰åˆ†åˆ†å‰²\n",
    "chunks = torch.chunk(cat_dim0, 2, dim=0)\n",
    "print(f\"ç­‰åˆ†ä¸º2å—: {len(chunks)}ä¸ªå¼ é‡\")\n",
    "print(f\"ç¬¬ä¸€å—:\\n{chunks[0]}\\n\")\n",
    "\n",
    "# æŒ‰æŒ‡å®šå¤§å°åˆ†å‰²\n",
    "splits = torch.split(cat_dim1, 3, dim=1)\n",
    "print(f\"æŒ‰å¤§å°3åˆ†å‰²: {len(splits)}ä¸ªå¼ é‡\")\n",
    "print(f\"ç¬¬ä¸€å—å½¢çŠ¶: {splits[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”„ 8. å¼ é‡ä¸NumPyçš„äº’è½¬\n",
    "\n",
    "PyTorchå¼ é‡å¯ä»¥ä¸NumPyæ•°ç»„æ— ç¼è½¬æ¢ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”„ PyTorchä¸NumPyäº’è½¬ï¼š\")\n",
    "\n",
    "# PyTorch â†’ NumPy\n",
    "pytorch_tensor = torch.randn(2, 3)\n",
    "numpy_array = pytorch_tensor.numpy()  # æ³¨æ„ï¼šå…±äº«å†…å­˜ï¼\n",
    "\n",
    "print(f\"PyTorchå¼ é‡:\\n{pytorch_tensor}\")\n",
    "print(f\"è½¬æ¢ä¸ºNumPy:\\n{numpy_array}\")\n",
    "print(f\"NumPyç±»å‹: {type(numpy_array)}\\n\")\n",
    "\n",
    "# NumPy â†’ PyTorch\n",
    "numpy_data = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "torch_from_numpy = torch.from_numpy(numpy_data)  # å…±äº«å†…å­˜\n",
    "torch_tensor = torch.tensor(numpy_data)  # å¤åˆ¶æ•°æ®\n",
    "\n",
    "print(f\"NumPyæ•°ç»„:\\n{numpy_data}\")\n",
    "print(f\"from_numpy():\\n{torch_from_numpy}\")\n",
    "print(f\"tensor():\\n{torch_tensor}\\n\")\n",
    "\n",
    "# âš ï¸ æ³¨æ„ï¼šå†…å­˜å…±äº«çš„å½±å“\n",
    "print(\"âš ï¸ å†…å­˜å…±äº«ç¤ºä¾‹ï¼š\")\n",
    "pytorch_tensor[0, 0] = 999\n",
    "print(f\"ä¿®æ”¹PyTorchå¼ é‡åçš„NumPyæ•°ç»„:\\n{numpy_array}\")\n",
    "print(\"ğŸ‘† æ³¨æ„ï¼šNumPyæ•°ç»„ä¹Ÿè¢«ä¿®æ”¹äº†ï¼(å…±äº«å†…å­˜)\")\n",
    "\n",
    "# å¦‚æœå¼ é‡åœ¨GPUä¸Šï¼Œéœ€è¦å…ˆç§»åˆ°CPU\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tensor = torch.randn(2, 2).cuda()\n",
    "    cpu_numpy = gpu_tensor.cpu().numpy()\n",
    "    print(f\"\\nGPUå¼ é‡è½¬NumPy: {cpu_numpy.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’» 9. è®¾å¤‡æ“ä½œ (CPU/GPU)\n",
    "\n",
    "PyTorchå¯ä»¥åœ¨ä¸åŒè®¾å¤‡ä¸Šè¿è¡Œï¼Œä¸»è¦æ˜¯CPUå’ŒGPUï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ’» è®¾å¤‡æ“ä½œï¼š\")\n",
    "\n",
    "# æ£€æŸ¥CUDAå¯ç”¨æ€§\n",
    "print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDAè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}\")\n",
    "    print(f\"å½“å‰CUDAè®¾å¤‡: {torch.cuda.current_device()}\")\n",
    "    print(f\"è®¾å¤‡åç§°: {torch.cuda.get_device_name()}\")\n",
    "\n",
    "print(f\"\\nä½¿ç”¨è®¾å¤‡: {device}\\n\")\n",
    "\n",
    "# åˆ›å»ºå¼ é‡åˆ°æŒ‡å®šè®¾å¤‡\n",
    "cpu_tensor = torch.randn(2, 3)  # é»˜è®¤åœ¨CPU\n",
    "print(f\"CPUå¼ é‡è®¾å¤‡: {cpu_tensor.device}\")\n",
    "\n",
    "# ç§»åŠ¨åˆ°GPU (å¦‚æœå¯ç”¨)\n",
    "gpu_tensor = cpu_tensor.to(device)\n",
    "print(f\"GPUå¼ é‡è®¾å¤‡: {gpu_tensor.device}\")\n",
    "\n",
    "# ç›´æ¥åœ¨GPUåˆ›å»ºå¼ é‡\n",
    "if torch.cuda.is_available():\n",
    "    direct_gpu = torch.randn(2, 3, device='cuda')\n",
    "    print(f\"ç›´æ¥GPUå¼ é‡è®¾å¤‡: {direct_gpu.device}\")\n",
    "\n",
    "# è®¾å¤‡é—´è¿ç®—è§„åˆ™\n",
    "print(\"\\nâš ï¸ é‡è¦ï¼šåªæœ‰ç›¸åŒè®¾å¤‡çš„å¼ é‡æ‰èƒ½è¿ç®—ï¼\")\n",
    "try:\n",
    "    # è¿™ä¼šå‡ºé”™ï¼ˆå¦‚æœæœ‰GPUçš„è¯ï¼‰\n",
    "    if torch.cuda.is_available():\n",
    "        result = cpu_tensor + direct_gpu  # ä¸åŒè®¾å¤‡å¼ é‡ç›¸åŠ \n",
    "except RuntimeError as e:\n",
    "    print(f\"é”™è¯¯: {e}\")\n",
    "\n",
    "# æ­£ç¡®åšæ³•ï¼šç¡®ä¿å¼ é‡åœ¨åŒä¸€è®¾å¤‡\n",
    "result = cpu_tensor.to(device) + gpu_tensor\n",
    "print(f\"\\næ­£ç¡®è¿ç®—ç»“æœè®¾å¤‡: {result.device}\")\n",
    "\n",
    "# å†…å­˜ä½¿ç”¨æƒ…å†µ (GPU)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nGPUå†…å­˜ä½¿ç”¨:\")\n",
    "    print(f\"å·²åˆ†é…: {torch.cuda.memory_allocated() / 1e6:.1f} MB\")\n",
    "    print(f\"å·²ç¼“å­˜: {torch.cuda.memory_reserved() / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ 10. å®æˆ˜ç»ƒä¹ ï¼šå›¾åƒæ•°æ®å¤„ç†\n",
    "\n",
    "è®©æˆ‘ä»¬ç”¨å¼ é‡æ“ä½œæ¥å¤„ç†ä¸€ä¸ªå®é™…çš„å›¾åƒæ•°æ®ç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ–¼ï¸ å®æˆ˜ï¼šå›¾åƒæ•°æ®å¤„ç†\")\n",
    "\n",
    "# æ¨¡æ‹Ÿä¸€æ‰¹RGBå›¾åƒæ•°æ®\n",
    "# å½¢çŠ¶: (æ‰¹æ¬¡å¤§å°, é€šé“æ•°, é«˜åº¦, å®½åº¦)\n",
    "batch_size, channels, height, width = 4, 3, 32, 32\n",
    "images = torch.randn(batch_size, channels, height, width)\n",
    "\n",
    "print(f\"ğŸ“Š å›¾åƒæ‰¹æ¬¡ä¿¡æ¯:\")\n",
    "print(f\"å½¢çŠ¶: {images.shape}\")\n",
    "print(f\"æ•°æ®ç±»å‹: {images.dtype}\")\n",
    "print(f\"æ•°å€¼èŒƒå›´: [{images.min():.3f}, {images.max():.3f}]\\n\")\n",
    "\n",
    "# 1. æ•°æ®æ ‡å‡†åŒ– (å¸¸è§é¢„å¤„ç†)\n",
    "normalized = (images - images.mean()) / images.std()\n",
    "print(f\"ğŸ“ˆ æ ‡å‡†åŒ–å:\")\n",
    "print(f\"å‡å€¼: {normalized.mean():.6f}\")\n",
    "print(f\"æ ‡å‡†å·®: {normalized.std():.6f}\\n\")\n",
    "\n",
    "# 2. é€šé“é‡æ’åº (BGR â†’ RGB)\n",
    "# å‡è®¾åŸå§‹æ˜¯BGRï¼Œè½¬æ¢ä¸ºRGB\n",
    "rgb_images = images[:, [2, 1, 0], :, :]  # äº¤æ¢é€šé“é¡ºåº\n",
    "print(f\"ğŸ¨ é€šé“é‡æ’åºåå½¢çŠ¶: {rgb_images.shape}\\n\")\n",
    "\n",
    "# 3. å›¾åƒç¼©æ”¾ (åŒçº¿æ€§æ’å€¼)\n",
    "import torch.nn.functional as F\n",
    "resized = F.interpolate(images, size=(64, 64), mode='bilinear', align_corners=False)\n",
    "print(f\"ğŸ” ç¼©æ”¾åå½¢çŠ¶: {resized.shape}\\n\")\n",
    "\n",
    "# 4. æ•°æ®å¢å¼ºï¼šéšæœºç¿»è½¬\n",
    "def random_flip(images, p=0.5):\n",
    "    \"\"\"éšæœºæ°´å¹³ç¿»è½¬å›¾åƒ\"\"\"\n",
    "    mask = torch.rand(images.size(0)) < p\n",
    "    flipped = images.clone()\n",
    "    flipped[mask] = torch.flip(flipped[mask], dims=[3])  # æ²¿å®½åº¦ç»´åº¦ç¿»è½¬\n",
    "    return flipped\n",
    "\n",
    "augmented = random_flip(images)\n",
    "print(f\"ğŸ² æ•°æ®å¢å¼ºåå½¢çŠ¶: {augmented.shape}\\n\")\n",
    "\n",
    "# 5. æ‰¹æ¬¡ç»Ÿè®¡\n",
    "print(f\"ğŸ“Š æ‰¹æ¬¡ç»Ÿè®¡:\")\n",
    "print(f\"æ¯ä¸ªå›¾åƒçš„å‡å€¼: {images.mean(dim=[1,2,3])}\")\n",
    "print(f\"æ¯ä¸ªé€šé“çš„å‡å€¼: {images.mean(dim=[0,2,3])}\")\n",
    "print(f\"ç©ºé—´ç»´åº¦çš„å‡å€¼: {images.mean(dim=[2,3]).shape}\")\n",
    "\n",
    "# 6. å±•å¹³ç”¨äºå…¨è¿æ¥å±‚\n",
    "flattened_for_fc = images.view(batch_size, -1)\n",
    "print(f\"\\nğŸ”— å±•å¹³ç”¨äºå…¨è¿æ¥å±‚: {flattened_for_fc.shape}\")\n",
    "print(f\"æ¯ä¸ªæ ·æœ¬ç‰¹å¾æ•°: {flattened_for_fc.size(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ æ€»ç»“ä¸å…³é”®è¦ç‚¹\n",
    "\n",
    "### ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ\n",
    "1. **å¼ é‡æ˜¯PyTorchçš„åŸºç¡€æ•°æ®ç»“æ„**ï¼Œç±»ä¼¼äºNumPyæ•°ç»„ä½†æ”¯æŒGPUè®¡ç®—\n",
    "2. **å½¢çŠ¶æ“ä½œæ˜¯å…³é”®æŠ€èƒ½**ï¼šreshape, view, transpose, permuteç­‰\n",
    "3. **è®¾å¤‡ç®¡ç†å¾ˆé‡è¦**ï¼šç¡®ä¿å¼ é‡åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šè¿›è¡Œè¿ç®—\n",
    "4. **å¹¿æ’­æœºåˆ¶**è®©ä¸åŒå½¢çŠ¶çš„å¼ é‡å¯ä»¥è¿›è¡Œè¿ç®—\n",
    "\n",
    "### ğŸ’¡ å®ç”¨æŠ€å·§\n",
    "- ä½¿ç”¨ `print_tensor_info()` å‡½æ•°æ£€æŸ¥å¼ é‡å±æ€§\n",
    "- åˆç†é€‰æ‹©æ•°æ®ç±»å‹ä»¥èŠ‚çœå†…å­˜\n",
    "- æ³¨æ„å†…å­˜å…±äº«ï¼š`numpy()` vs `tensor()`\n",
    "- GPUå¼ é‡éœ€è¦ç§»åˆ°CPUæ‰èƒ½è½¬æ¢ä¸ºNumPy\n",
    "\n",
    "### ğŸš€ ä¸‹ä¸€æ­¥å­¦ä¹ \n",
    "- è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶ (Autograd)\n",
    "- ç¥ç»ç½‘ç»œæ„å»º (nn.Module)\n",
    "- æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
    "- æ•°æ®åŠ è½½å’Œé¢„å¤„ç†\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ† ç»ƒä¹ ä»»åŠ¡\n",
    "\n",
    "å®Œæˆä»¥ä¸‹ç»ƒä¹ æ¥å·©å›ºå¼ é‡æ“ä½œï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ† ç»ƒä¹ ä»»åŠ¡ï¼š\")\n",
    "\n",
    "# ç»ƒä¹ 1: åˆ›å»ºä¸€ä¸ª3x4çš„éšæœºçŸ©é˜µï¼Œç„¶å:\n",
    "# - è®¡ç®—æ¯è¡Œçš„å’Œ\n",
    "# - æ‰¾å‡ºæœ€å¤§å€¼åŠå…¶ä½ç½®\n",
    "# - è½¬ç½®çŸ©é˜µ\n",
    "print(\"ğŸ“ ç»ƒä¹ 1: çŸ©é˜µæ“ä½œ\")\n",
    "matrix = torch.randn(3, 4)\n",
    "print(f\"åŸçŸ©é˜µ:\\n{matrix}\")\n",
    "\n",
    "# ä½ çš„ä»£ç åœ¨è¿™é‡Œ...\n",
    "row_sums = matrix.sum(dim=1)\n",
    "max_val, max_idx = matrix.max(), matrix.argmax()\n",
    "transposed = matrix.T\n",
    "\n",
    "print(f\"æ¯è¡Œå’Œ: {row_sums}\")\n",
    "print(f\"æœ€å¤§å€¼: {max_val}, ä½ç½®: {max_idx}\")\n",
    "print(f\"è½¬ç½®åå½¢çŠ¶: {transposed.shape}\\n\")\n",
    "\n",
    "# ç»ƒä¹ 2: åˆ›å»ºä¸¤ä¸ª2x3çŸ©é˜µï¼Œè¿›è¡Œå…ƒç´ çº§ä¹˜æ³•å’ŒçŸ©é˜µä¹˜æ³•\n",
    "print(\"ğŸ“ ç»ƒä¹ 2: çŸ©é˜µè¿ç®—\")\n",
    "A = torch.randn(2, 3)\n",
    "B = torch.randn(3, 2)  # æ³¨æ„å½¢çŠ¶ä»¥ä¾¿çŸ©é˜µä¹˜æ³•\n",
    "\n",
    "# ä½ çš„ä»£ç åœ¨è¿™é‡Œ...\n",
    "print(f\"Aå½¢çŠ¶: {A.shape}, Bå½¢çŠ¶: {B.shape}\")\n",
    "print(f\"çŸ©é˜µä¹˜æ³• A@B å½¢çŠ¶: {(A @ B).shape}\")\n",
    "\n",
    "print(\"\\nğŸ‰ æ­å–œå®Œæˆå¼ é‡åŸºç¡€å­¦ä¹ ï¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
